{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORrvot7Cj0sXAoMXW2l+Fy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGnSe3D7gsTi","executionInfo":{"status":"ok","timestamp":1711991112583,"user_tz":-330,"elapsed":15147,"user":{"displayName":"Aanchal Gupta","userId":"16542473823371858485"}},"outputId":"72b09ef7-2940-4cbf-d801-dfc644d40f3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["\n","!pip install nltk\n","\n","import nltk\n","from nltk import pos_tag, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.chunk import ne_chunk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n"]},{"cell_type":"code","source":["# sentence = \"Albert einstein was born in Ulm, Germany.\"\n","sentence = \"The Arab Nationalists aimed, in part, to remove British imperial influence in Iraq.\""],"metadata":{"id":"f9cwhymFgvAR","executionInfo":{"status":"ok","timestamp":1711991112584,"user_tz":-330,"elapsed":6,"user":{"displayName":"Aanchal Gupta","userId":"16542473823371858485"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","# Tokenize the sentence\n","words = word_tokenize(sentence)\n","\n","# Remove stop words\n","stop_words = set(stopwords.words('english'))\n","words = [word for word in words if word.lower() not in stop_words]\n","\n","# Perform part-of-speech tagging\n","tagged_words = pos_tag(words)\n","\n","noun_phrases = []\n","current_noun_phrase = \"\"\n","\n","# Loop through tagged words to extract noun phrases\n","for i in range(len(tagged_words)):\n","    word, pos = tagged_words[i]\n","    if pos.startswith('JJ'):  # If it's an adjective\n","        if i < len(tagged_words) - 1 and tagged_words[i + 1][1].startswith('NNP') or tagged_words[i + 1][1].startswith('NN') or tagged_words[i + 1][1].startswith('NNS'):\n","            current_noun_phrase += word + \" \"  # Add the adjective to the current noun phrase\n","    elif pos.startswith('NNP') or pos.startswith('NN') or pos.startswith('NNS'):  # If it's a proper noun or noun\n","        current_noun_phrase += word + \" \"  # Add the word to the current noun phrase\n","        noun_phrases.append(current_noun_phrase.strip())  # Add the noun phrase to the list\n","        current_noun_phrase = \"\"  # Reset the variable for the next noun phrase\n","\n","# If there's still a pending noun phrase after the loop ends\n","if current_noun_phrase:\n","    noun_phrases.append(current_noun_phrase.strip())\n","\n","# Print the array of noun phrases\n","print(noun_phrases)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYOYdHrYnwBU","executionInfo":{"status":"ok","timestamp":1711991666368,"user_tz":-330,"elapsed":418,"user":{"displayName":"Aanchal Gupta","userId":"16542473823371858485"}},"outputId":"4b730212-90d6-4b6e-b93f-a233d8024ebe"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['Arab Nationalists', 'part', 'British', 'imperial influence', 'Iraq']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"v4dy7GNdnzKM"},"execution_count":null,"outputs":[]}]}